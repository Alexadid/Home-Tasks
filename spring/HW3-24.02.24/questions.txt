1. Ситуации для использования set и map

Начнём с set. Во-первых, уникальность элементов - повторяющиеся элементы удаляются сами по себе). Во-вторых, отсортированность элементов  - отсортированы автоматически (по умолчанию по возрастанию). В-третьих, у set эффективные операции поиска (временная сложность O(log N)), так что использовать стоит при необходимости часто проверять наличие элемента. В том числе, поиск относительно заданного элемента (lower_bound, upper_bound).

А теперь поговорим про map. Очевидной ситуацией для использования является необходимость связать значения с ключами. Это позволяет быстро получать значение, связанное с определенным ключом. Более того, каждый ключ в map должен быть уникальным. Если попытаться вставить пару ключ-значение с ключом, который уже существует, карта обновит существующий ключ новым значением. Как и set, элементы в map хранятся в отсортированном порядке на основе ключа.

2. Требования к хэш-функциям

Начнём с равномерности (от которой я устал за время решения задач). Значения хэша функции должны быть равномерно распределены, чтобы минимизировать коллизии, хотя избавиться от них полностью крайне сложно, а иногда невозможно. Очевидным требованием со стороны криптографии является детерминированность - при одинаковых входных данных хэш-функция всегда должна выдавать одинаковые выходные данные. Отсюда же следует то, что функция должна быстро вычислять значения хэша для поддержания общей производительности (таким образом, нельзя установить связь между длительностью вычисления хэша и исходными данными). Также криптография требует того, что любое небольшое изменение входных данных должно приводить к значительному изменению хэша. Если бы этого не было, было возможно реконструировать исходное значение...

3. Коллизии в хэш-таблицах. "Идеальные" хэш-функции

Начнём с хэш-таблиц. Коллизии здесь объяснимы двумя причинами: ограниченный размер таблицы (значений хэшей потенциально может быть бесконечное количество в отличие от размеров таблицы) и качество хэш-функции (отсутствие равномерности -> больше элементов 'свалятся' в один из сегментов таблицы). Исправить коллизии можно несколькими способами: метод цепочек (в каждом блоке хранится список (или цепочка) всех элементов, которые хэшируются в одном и том же слоте; коллизии разрешаются путем добавления нового элемента в список) и открытой адресацией (при возникновении коллизии открытая адресация ищет следующий доступный слот в соответствии с определенной последовательностью (линейное зондирование, квадратичное зондирование или двойное хэширование) и помещает туда новый элемент; при этом резко возрастает сложность удаления и доступа к элементам).

А теперь можно поговорить про "идеальные" хэш-функции. Создание такой функции, гарантирующей отсутствие коллизий для любого набора входных ключей, теоретически невозможно, если набор всех возможных входных данных больше, чем количество доступных хэш-значений. Это связано с принципом Дирихле (ящики и голуби). С точки зрения хэш-функций, если существует больше потенциальных ключей, которые хэшируют значения, некоторые ключи должны быть сопоставлены с одним и тем же хэш-значением, что приводит к коллизиям. Конечно, могут возникать ситуации, в которых количество потенциальных ключей ограничено, и создание достаточно большой хэш-таблицы возможно... Тем не менее, требования предъявляемые криптографией скорее всего сделают такую затею бессмысленной.

4. Сложность операций в хэш-таблицах

Наихудший сценарий возникает из-за:
А) коллизий;
Б) методов их разрешения: метода цепочки (если много ключей хэшируются в одном и том же сегменте, операции требуют обхода длинного списка, что приводит к сложности O(N)), открытой адресации (высокая частота коллизий требует многократного поиска пустого элемента, потенциально проверяя каждый из них и приводя к сложности O(N));
В) Плохая хэш-функция или высокая загрузка (неравномерное распределение ключей или полностью заполненная хэш-таблица увеличивают количество коллизий);

5. Итерация по хэш-таблице только в одну сторону

Дело в структуре хэш-таблиц и их назначении. Порядок итерации по таблице задаётся порядком сегментов ввиду непредсказуемости генерируемых хэшей. Это, в свою очередь, ускоряет движение по таблице, ускоряя процесс доступа к элемента. Таким образом, реализация механизмов обратной итерации попросту бессмысленна, она бы пошла в разрез с самой целью разразработки хэш-таблицы, ориентированной на эффективный доступ на основе ключей. Следовательно, понятие "предыдущий" или "следующий" в хэш-таблице не столь четко определено, как в последовательно упорядоченных структурах данных.

6. Structure binding

Structure binding позволяет распаковывать элементы tuple, pair, массивов или структур в отдельные переменные в одном операторе, повышая читаемость и эффективность кода. Например, когда функция возвращает данные, упакованные в tuple или pair, structure binding позволяет распаковать эти данные в переменные напрямую (без дополнительных циклов и подобного). Также, structure binding упрощает работу в циклах с использованием map. Сокращение количества репетативного кода и делая операции более явными, structure binding приводит к тому, что код становится более читабельным и простым в обслуживании.

7. В multimap нет оператора индексирования... Как же так?!

Отсутствие оператора индексации в multimap, в отличие от map, связано с тем, что multimap допускает использование нескольких элементов с одним и тем же ключом, что усложняет семантику прямого доступа. Оператор индексации в map служит двум целям: доступ к существующим элементам и вставка новых, если ключ не существует. Однако в multimap такое поведение было бы неоднозначным, поскольку неясно, к какому значению следует обращаться или изменять. Кроме того, multimap разработан для сценариев, где обычной практикой является итерация по элементам с одинаковым ключом. Для управления элементами в multimap STL предоставляет такие функции, как find, equal_range, lower_bound и upper_bound, которые обеспечивают явную и безопасную (!) обработку элементов в соответствии с предполагаемым использованием multimap.

8. Определение компараторов, хэш-функций и хэш-таблиц

Чтобы настроить пользовательскую сортировку в map или set, можно определить компаратор, используя указатель на функцию, функтор или лямбда-выражение. Например, функтор для набора может выглядеть следующим образом:

struct Compare
{
	bool operator()(int a, int b) const
	{
		return a < b;
	}
};
std::set<int, Compare> mySet;

Для хэш-таблиц, таких как unordered_map или unordered_set, пользовательские хэш-функции определяются с использованием функторов. Базовым функтором хэш-функции может быть:

struct KeyHash
{
	std::size_t operator()(const KeyType& k) const
	{
		// А вот здесь был бы хэширующий код
		return calculatedHash;
	}
};
std::unordered_map<KeyType, ValueType, KeyHash> myUnorderedMap;

9. Почему ключ в map должен быть константным?

Ключи должны быть константным, чтобы обеспечить целостность и упорядоченность внутренней структуры map (сбалансированное двоичное дерево). Прямое изменение ключа может привести к аннулированию порядка расположения деревьев, что приведет к неправильному поведению или неэффективности операций с map. Даже если пара ключ-значение обрабатывается как константа во время итерации, предотвращая прямое изменение ключа, это постоянство необходимо для поддержания порядка сортировки map на основе ключа. Если бы ключам было разрешено меняться, это могло бы нарушить строгий порядок, что потенциально привело бы к потере целостности данных и эффективности доступа.

10. Операция рехэширования

Рехеширование имеет решающее значение для поддержания эффективности и быстродействия хэш-таблиц. Оно включает изменение количества сегментов и перераспределение элементов, вызванное изменениями коэффициента загрузки. Высокий коэффициент загрузки увеличивает риски коллизий, ухудшая время доступа. Повторное хеширование уменьшает коэффициент загрузки и коллизии за счёт распределения элементов по большему количеству сегментов, стремясь сохранить временную сложность операций на уровне O(1). Запуск со слишком большим количеством сегментов может привести к потере памяти. Таким образом, рехэширование позволяет динамически корректировать размер хэш-таблицы, балансируя между эффективным использованием памяти и оптимальной производительностью. Как-то так...